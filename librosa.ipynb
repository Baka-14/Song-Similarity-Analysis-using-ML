{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m248.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m509.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (1.1.0)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.56.4-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m439.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m561.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (1.23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (4.2.0)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m535.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting msgpack>=1.0\n",
      "  Downloading msgpack-1.0.4-cp39-cp39-macosx_11_0_arm64.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m668.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from librosa) (1.0.2)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.3-cp39-cp39-macosx_11_0_arm64.whl (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.5/377.5 kB\u001b[0m \u001b[31m653.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (57.4.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp39-cp39-macosx_11_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m181.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=f9eec86816d2945ff898f8cd4fd3af0533db285972162572c7fd23be12467f98\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/7a/6a/b0/92760a6d6bc2bff5464970af910c0b0b921390993f3199cdf7\n",
      "Successfully built audioread\n",
      "Installing collected packages: msgpack, appdirs, soxr, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed appdirs-1.4.4 audioread-3.0.0 lazy-loader-0.1 librosa-0.10.0 llvmlite-0.39.1 msgpack-1.0.4 numba-0.56.4 pooch-1.6.0 soundfile-0.12.1 soxr-0.3.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between the two songs: 0.969208836555481\n",
      "Euclidean distance similarity between the two songs: 0.6888452096219889\n",
      "Manhattan distance similarity between the two songs: 0.4240664642133662\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Chalamelara - 6Rings (feat. GWS .mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Calculate the similarity between the embeddings using different metrics\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "euclidean_sim = 1 / (1 + euclidean_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "manhattan_sim = 1 / (1 + manhattan_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# correlation_sim = 1 / (1 + correlation(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# canberra_sim = 1 / (1 + canberra(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity between the two songs: {cosine_sim}\")\n",
    "print(f\"Euclidean distance similarity between the two songs: {euclidean_sim}\")\n",
    "print(f\"Manhattan distance similarity between the two songs: {manhattan_sim}\")\n",
    "# print(f\"Correlation similarity between the two songs: {correlation_sim}\")\n",
    "# print(f\"Canberra similarity between the two songs: {canberra_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between the two songs: 0.9650315642356873\n",
      "Euclidean distance similarity between the two songs: 0.648171249144015\n",
      "Manhattan distance similarity between the two songs: 0.3837546622177287\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Kid Cudi, Don Toliver, Steve Aoki, & Dot Da Genius - Burrow (Official Lyric Video).mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Calculate the similarity between the embeddings using different metrics\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "euclidean_sim = 1 / (1 + euclidean_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "manhattan_sim = 1 / (1 + manhattan_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# correlation_sim = 1 / (1 + correlation(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# canberra_sim = 1 / (1 + canberra(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity between the two songs: {cosine_sim}\")\n",
    "print(f\"Euclidean distance similarity between the two songs: {euclidean_sim}\")\n",
    "print(f\"Manhattan distance similarity between the two songs: {manhattan_sim}\")\n",
    "# print(f\"Correlation similarity between the two songs: {correlation_sim}\")\n",
    "# print(f\"Canberra similarity between the two songs: {canberra_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between the two songs: 0.9890444874763489\n",
      "Euclidean distance similarity between the two songs: 0.7659434087553642\n",
      "Manhattan distance similarity between the two songs: 0.5063512124438321\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Samaja Vara Gamana _ Tyagaraja Krithi.mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Calculate the similarity between the embeddings using different metrics\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "euclidean_sim = 1 / (1 + euclidean_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "manhattan_sim = 1 / (1 + manhattan_distances(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# correlation_sim = 1 / (1 + correlation(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "# canberra_sim = 1 / (1 + canberra(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0])\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity between the two songs: {cosine_sim}\")\n",
    "print(f\"Euclidean distance similarity between the two songs: {euclidean_sim}\")\n",
    "print(f\"Manhattan distance similarity between the two songs: {manhattan_sim}\")\n",
    "# print(f\"Correlation similarity between the two songs: {correlation_sim}\")\n",
    "# print(f\"Canberra similarity between the two songs: {canberra_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9650315642356873\n",
      "Pearson correlation coefficient: -0.36648099031660863\n",
      "Jaccard similarity: 1.0\n",
      "Hamming distance: 12\n",
      "Sørensen–Dice coefficient: 0.8064578568062436\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Kid Cudi, Don Toliver, Steve Aoki, & Dot Da Genius - Burrow (Official Lyric Video).mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(embedding1, embedding2)\n",
    "\n",
    "# Compute Jaccard similarity\n",
    "jaccard_sim = jaccard_score(embedding1 > 0, embedding2 > 0)\n",
    "\n",
    "# Compute Hamming distance\n",
    "hamming_dist = np.count_nonzero(embedding1 != embedding2)\n",
    "\n",
    "# Compute Sørensen–Dice coefficient\n",
    "sorensen_dice = 2 * np.sum(np.minimum(embedding1, embedding2)) / np.sum(embedding1 + embedding2)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity: {cosine_sim}\")\n",
    "print(f\"Pearson correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Jaccard similarity: {jaccard_sim}\")\n",
    "print(f\"Hamming distance: {hamming_dist}\")\n",
    "print(f\"Sørensen–Dice coefficient: {sorensen_dice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.969208836555481\n",
      "Pearson correlation coefficient: 0.039492358238769024\n",
      "Jaccard similarity: 1.0\n",
      "Hamming distance: 12\n",
      "Sørensen–Dice coefficient: 0.8291796187863562\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Chalamelara - 6Rings (feat. GWS .mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(embedding1, embedding2)\n",
    "\n",
    "# Compute Jaccard similarity\n",
    "jaccard_sim = jaccard_score(embedding1 > 0, embedding2 > 0)\n",
    "\n",
    "# Compute Hamming distance\n",
    "hamming_dist = np.count_nonzero(embedding1 != embedding2)\n",
    "\n",
    "# Compute Sørensen–Dice coefficient\n",
    "sorensen_dice = 2 * np.sum(np.minimum(embedding1, embedding2)) / np.sum(embedding1 + embedding2)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity: {cosine_sim}\")\n",
    "print(f\"Pearson correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Jaccard similarity: {jaccard_sim}\")\n",
    "print(f\"Hamming distance: {hamming_dist}\")\n",
    "print(f\"Sørensen–Dice coefficient: {sorensen_dice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9890444874763489\n",
      "Pearson correlation coefficient: 0.6585222504060412\n",
      "Jaccard similarity: 1.0\n",
      "Hamming distance: 12\n",
      "Sørensen–Dice coefficient: 0.8723443710362477\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('Samaja Vara Gamana _ Tyagaraja Krithi.mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(embedding1, embedding2)\n",
    "\n",
    "# Compute Jaccard similarity\n",
    "jaccard_sim = jaccard_score(embedding1 > 0, embedding2 > 0)\n",
    "\n",
    "# Compute Hamming distance\n",
    "hamming_dist = np.count_nonzero(embedding1 != embedding2)\n",
    "\n",
    "# Compute Sørensen–Dice coefficient\n",
    "sorensen_dice = 2 * np.sum(np.minimum(embedding1, embedding2)) / np.sum(embedding1 + embedding2)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity: {cosine_sim}\")\n",
    "print(f\"Pearson correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Jaccard similarity: {jaccard_sim}\")\n",
    "print(f\"Hamming distance: {hamming_dist}\")\n",
    "print(f\"Sørensen–Dice coefficient: {sorensen_dice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9829627275466919\n",
      "Pearson correlation coefficient: 0.2322052994630464\n",
      "Jaccard similarity: 1.0\n",
      "Hamming distance: 12\n",
      "Sørensen–Dice coefficient: 0.8156430798920383\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Load the audio files\n",
    "song1, sr1 = librosa.load('LSD - Thunderclouds (Official Video) ft. Sia, Diplo, Labrinth.mp3')\n",
    "song2, sr2 = librosa.load('చలమేలరా (Chalamelara - Margahindolam).mp3')\n",
    "\n",
    "# Compute the chroma features of each song\n",
    "chroma1 = librosa.feature.chroma_stft(y=song1, sr=sr1)\n",
    "chroma2 = librosa.feature.chroma_stft(y=song2, sr=sr2)\n",
    "\n",
    "# Take the mean of each feature across time to create an embedding\n",
    "embedding1 = np.mean(chroma1.T, axis=0)\n",
    "embedding2 = np.mean(chroma2.T, axis=0)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(embedding1, embedding2)\n",
    "\n",
    "# Compute Jaccard similarity\n",
    "jaccard_sim = jaccard_score(embedding1 > 0, embedding2 > 0)\n",
    "\n",
    "# Compute Hamming distance\n",
    "hamming_dist = np.count_nonzero(embedding1 != embedding2)\n",
    "\n",
    "# Compute Sørensen–Dice coefficient\n",
    "sorensen_dice = 2 * np.sum(np.minimum(embedding1, embedding2)) / np.sum(embedding1 + embedding2)\n",
    "\n",
    "# Print the similarity scores\n",
    "print(f\"Cosine similarity: {cosine_sim}\")\n",
    "print(f\"Pearson correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Jaccard similarity: {jaccard_sim}\")\n",
    "print(f\"Hamming distance: {hamming_dist}\")\n",
    "print(f\"Sørensen–Dice coefficient: {sorensen_dice}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
